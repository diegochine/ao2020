{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian Open 2020: Winner Predictor\n",
    "## Web Intelligence Course, Ca' Foscari University, A.Y. 2019/2020\n",
    "#### Diego Chinellato, 867637 - Giorgia Campardo, 867928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('dataset.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext = pd.read_excel('2019+.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23634 entries, 0 to 23633\n",
      "Data columns (total 42 columns):\n",
      "ATP           23634 non-null int64\n",
      "Location      23634 non-null object\n",
      "Tournament    23634 non-null object\n",
      "Date          23634 non-null datetime64[ns]\n",
      "Series        23634 non-null object\n",
      "Court         23634 non-null object\n",
      "Surface       23634 non-null object\n",
      "Round         23634 non-null object\n",
      "Best of       23634 non-null int64\n",
      "Winner        23634 non-null object\n",
      "Loser         23634 non-null object\n",
      "WRank         23624 non-null float64\n",
      "LRank         23586 non-null float64\n",
      "WPts          23626 non-null float64\n",
      "LPts          23587 non-null float64\n",
      "W1            23483 non-null float64\n",
      "L1            23485 non-null float64\n",
      "W2            23260 non-null float64\n",
      "L2            23260 non-null float64\n",
      "W3            11173 non-null float64\n",
      "L3            11173 non-null float64\n",
      "W4            2200 non-null float64\n",
      "L4            2200 non-null float64\n",
      "W5            816 non-null float64\n",
      "L5            816 non-null float64\n",
      "Wsets         23482 non-null float64\n",
      "Lsets         23480 non-null float64\n",
      "Comment       23634 non-null object\n",
      "B365W         23540 non-null float64\n",
      "B365L         23561 non-null float64\n",
      "EXW           20834 non-null object\n",
      "EXL           20839 non-null float64\n",
      "LBW           20172 non-null float64\n",
      "LBL           20183 non-null float64\n",
      "PSW           23513 non-null float64\n",
      "PSL           23513 non-null float64\n",
      "SJW           10314 non-null float64\n",
      "SJL           10321 non-null float64\n",
      "MaxW          23609 non-null float64\n",
      "MaxL          23609 non-null float64\n",
      "AvgW          23609 non-null float64\n",
      "AvgL          23609 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(29), int64(2), object(10)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ext.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elo_rankings(data):\n",
    "    \"\"\"\n",
    "    Given the list on matches in chronological order, for each match, computes \n",
    "    the elo ranking of the 2 players at the beginning of the match\n",
    "    \"\"\"\n",
    "    print(\"Elo rankings computing...\")\n",
    "    players=list(pd.Series(list(data.Winner)+list(data.Loser)).value_counts().index)\n",
    "    elo=pd.Series(np.ones(len(players))*1500,index=players)\n",
    "    ranking_elo=[(1500,1500)]\n",
    "    for i in range(1,len(data)):\n",
    "        w=data.iloc[i-1,:].Winner\n",
    "        l=data.iloc[i-1,:].Loser\n",
    "        elow=elo[w]\n",
    "        elol=elo[l]\n",
    "        pwin=1 / (1 + 10 ** ((elol - elow) / 400))    \n",
    "        K_win=32\n",
    "        K_los=32\n",
    "        new_elow=elow+K_win*(1-pwin)\n",
    "        new_elol=elol-K_los*(1-pwin)\n",
    "        elo[w]=new_elow\n",
    "        elo[l]=new_elol\n",
    "        ranking_elo.append((elo[data.iloc[i,:].Winner],elo[data.iloc[i,:].Loser])) \n",
    "    ranking_elo=pd.DataFrame(ranking_elo,columns=[\"elo_winner\",\"elo_loser\"])    \n",
    "    ranking_elo[\"proba_elo\"]=1 / (1 + 10 ** ((ranking_elo[\"elo_loser\"] - ranking_elo[\"elo_winner\"]) / 400))   \n",
    "    return ranking_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df,\n",
    "                    max_date=2014,\n",
    "                    features_to_drop=[], \n",
    "                    missing_values=\"drop\", \n",
    "                    drop_first=False):\n",
    "    \"\"\"\n",
    "    Processes raw data and returns a tuple (X, Y) where X is the cleaned dataset and Y is the array of labels.\n",
    "    \"\"\"\n",
    "    # Sort by date to calculate ELO\n",
    "    X = df.sort_values(by='Date')\n",
    "    \n",
    "    # Drop old data\n",
    "    X = X.drop(index=X[X['Date'] < pd.Timestamp(max_date, 1, 1)].index)\n",
    "    \n",
    "    # Drop unuseful columns\n",
    "    features_to_drop += ['ATP', 'Location', 'Tournament', 'Date', 'Comment', \n",
    "                         'WPts', 'LPts', 'Wsets', 'Lsets', \n",
    "                         'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', \n",
    "                         'B365W', 'B365L', 'EXW', 'EXL', 'LBW', 'LBL', 'PSW', 'PSL', 'SJW', 'SJL']\n",
    "    X = X.drop(columns=features_to_drop)\n",
    "    \n",
    "    # Deal with missing values\n",
    "    X['WRank'] = X['WRank'].fillna(value=X['WRank'].max()+100).astype(int)\n",
    "    X['LRank'] = X['LRank'].fillna(value=X['LRank'].max()+100).astype(int)\n",
    "    \n",
    "    if missing_values == 'drop':\n",
    "        X = X.dropna()\n",
    "    elif missing_values == 'custom':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Wrong parameter: missing_values')\n",
    "\n",
    "    # Convert ordinal features to int (higher value means more important)\n",
    "    series = ['ATP250', 'ATP500', 'Masters 1000', 'Masters Cup', 'Grand Slam']\n",
    "    series2int = {s: i for i, s in enumerate(series)}\n",
    "    rounds2int = {'1st Round': 0,\n",
    "                  '2nd Round': 1,\n",
    "                  '3rd Round': 2,\n",
    "                  '4th Round': 3,\n",
    "                  'Round Robin': 4,\n",
    "                  'Quarterfinals': 5,\n",
    "                  'Semifinals': 6,\n",
    "                  'The Final': 7,\n",
    "                 }\n",
    "    X = X.replace({'Round': rounds2int, 'Series': series2int})\n",
    "    \n",
    "    # Convert court to binary\n",
    "    X = X.replace({'Court': {'Outdoor': 0, 'Indoor': 1}})\n",
    "    \n",
    "    # One hot encode categorical features into binary features\n",
    "    X = pd.get_dummies(X, prefix=['Surface_'], columns=['Surface'], drop_first=drop_first)\n",
    "    \n",
    "    # Convert players to numeric ?\n",
    "    players = set(X['Winner']) | set(X['Loser'])\n",
    "    players_to_id = {}\n",
    "    for i, player in enumerate(players):\n",
    "        players_to_id[player] = i\n",
    "    X = X.replace({'Winner': players_to_id, 'Loser': players_to_id})\n",
    "    X = X.astype({'Winner':int, 'Loser':int})\n",
    "\n",
    "    X = X.rename(columns={'Winner':'1st Player', 'Loser':'2nd Player', \n",
    "                          'WRank':'P1Rank', 'LRank':'P2Rank', \n",
    "                          'MaxW':'MaxP1', 'MaxL':'MaxP2', \n",
    "                          'AvgW':'AvgP1', 'AvgL':'AvgP2'})\n",
    "    \n",
    "    # Generate labels\n",
    "    Y = np.concatenate([np.ones(X.shape[0], dtype=int), np.zeros(X.shape[0], dtype=int)])\n",
    "    # Swap columns and concatenate to data\n",
    "    tmp = X.copy()\n",
    "    cols_to_swap = ['1st Player', '2nd Player', 'P1Rank', 'P2Rank', 'MaxP1', 'MaxP2',  'AvgP1',  'AvgP2']\n",
    "    cols_swapped = ['2nd Player', '1st Player', 'P2Rank', 'P1Rank', 'MaxP2', 'MaxP1',  'AvgP2',  'AvgP1']\n",
    "    tmp[cols_to_swap] = tmp[cols_swapped]\n",
    "    tmp.index = np.array(range(X.shape[0] + 1, X.shape[0] * 2 + 1))\n",
    "    X = pd.concat((X, tmp))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = preprocess_data(df_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare type 'Timestamp' with type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-acef0d15b5df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-f484ce517419>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(df, max_date, features_to_drop, missing_values, drop_first)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Drop old data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Drop unuseful columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1767\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1768\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1603\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslibs/timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare type 'Timestamp' with type 'str'"
     ]
    }
   ],
   "source": [
    "a, b = preprocess_data(x)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train set, validation set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.20)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    # Builds a decision tree and performs automatic hyper-parameters tuning\n",
    "    scores = []\n",
    "    for criterion in ('gini', 'entropy'):\n",
    "        for depth in range(5, 50):\n",
    "            for leaves in range(5, 20):\n",
    "                dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                            criterion=criterion,\n",
    "                                            max_depth=depth)\n",
    "                dt.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=dt.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, criterion, depth, leaves)]\n",
    "    best = max(scores)\n",
    "    acc, criterion, depth, leaves = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('Criterion:', criterion)\n",
    "    print('Max depth:', depth)\n",
    "    print('Max leaves:', leaves)\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                     criterion=criterion,\n",
    "                                     max_depth=depth)\n",
    "    dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bagging_classifier(X_train, Y_train, X_valid, Y_valid, dt_params):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    scores = []\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=dt_params[3],\n",
    "                                criterion=dt_params[1],\n",
    "                                max_depth=dt_params[2])\n",
    "    for bootstrap in (True, False):\n",
    "        for n_est in range(10, 201, 20):\n",
    "            for max_samples in (0.25, 0.50, 0.75, 1.0):\n",
    "                bagged_dt = BaggingClassifier(dt, bootstrap=bootstrap,\n",
    "                                              n_estimators=n_est,\n",
    "                                              max_samples=max_samples,\n",
    "                                              n_jobs=-1)\n",
    "                bagged_dt.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=bagged_dt.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, bootstrap, n_est, max_samples)]\n",
    "    best = max(scores)\n",
    "    acc, bootsrap, n_est, max_samples = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('Boostrap:', bootsrap)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Max samples:', max_samples)\n",
    "    bagged_dt = BaggingClassifier(dt, \n",
    "                                  bootstrap=bootstrap,\n",
    "                                  n_estimators=n_est, \n",
    "                                  max_samples=max_samples)\n",
    "    bagged_dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return bagged_dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adaboost(X_train, Y_train, X_valid, Y_valid, dt_params):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    scores = []\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=dt_params[3],\n",
    "                                criterion=dt_params[1],\n",
    "                                max_depth=dt_params[2])\n",
    "    for n_est in range(50, 301, 25):\n",
    "        for learning_rate in (0.50, 0.75, 1.0, 1.5):\n",
    "            boosted_dt = AdaBoostClassifier(dt,\n",
    "                                            n_estimators=n_est,\n",
    "                                            learning_rate=learning_rate)\n",
    "            boosted_dt.fit(X_train, Y_train)\n",
    "            valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=bagged_dt.predict(X_valid)), 3)\n",
    "            scores += [(valid_acc, n_est, learning_rate)]\n",
    "    best = max(scores)\n",
    "    acc, n_est, learning_rate = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Learning rate:', learning_rate)\n",
    "    boosted_dt = AdaBoostClassifier(dt,\n",
    "                                    n_estimators=n_est,\n",
    "                                    learning_rate=learning_rate)\n",
    "    boosted_dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return boosted_dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_forest(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    scores = []\n",
    "    for n_est in range(50, 301, 25):\n",
    "        for criterion in ('gini', 'entropy'):\n",
    "            for bootstrap in (True, False):\n",
    "                rf = RandomForestClassifier(n_estimators=n_est,\n",
    "                                               bootstrap=bootstrap,\n",
    "                                               criterion=criterion,\n",
    "                                               n_jobs=-1)\n",
    "                rf.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=rf.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, n_est, criterion, bootstrap)]\n",
    "    best = max(scores)\n",
    "    acc, n_est, criterion, bootstrap = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Criterion:', criterion)\n",
    "    print('Bootstrap:', bootstrap)\n",
    "    rf = RandomForestClassifier(n_estimators=n_est,\n",
    "                               bootstrap=bootstrap,\n",
    "                               criterion=criterion,\n",
    "                               n_jobs=-1)\n",
    "    rf.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return rf, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.695\n",
      "Criterion: gini\n",
      "Max depth: 6\n",
      "Max leaves: 19\n"
     ]
    }
   ],
   "source": [
    "dt, dt_params = build_decision_tree(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.695\n",
      "Boostrap: True\n",
      "N. estimators: 100\n",
      "Max samples: 0.5\n"
     ]
    }
   ],
   "source": [
    "bagged_dt, bagged_params = build_bagging_classifier(X_train, Y_train, X_valid, Y_valid, dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.695\n",
      "N. estimators: 300\n",
      "Learning rate: 1.5\n"
     ]
    }
   ],
   "source": [
    "boosted_dt, boosted_params = build_adaboost(X_train, Y_train, X_valid, Y_valid, dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.687\n",
      "N. estimators: 225\n",
      "Criterion: gini\n",
      "Bootstrap: True\n"
     ]
    }
   ],
   "source": [
    "rf, rf_params = build_random_forest(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(X, Y, models):\n",
    "    for model in models:\n",
    "        print('Algorithm:', str(type(model)).split('.')[-1][:-2])\n",
    "        rep = classification_report(y_true=Y, y_pred=model.predict(X))\n",
    "        print(rep)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68      3132\n",
      "           1       0.68      0.72      0.70      3137\n",
      "\n",
      "    accuracy                           0.69      6269\n",
      "   macro avg       0.69      0.69      0.69      6269\n",
      "weighted avg       0.69      0.69      0.69      6269\n",
      "\n",
      "\n",
      "Algorithm: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3132\n",
      "           1       0.70      0.68      0.69      3137\n",
      "\n",
      "    accuracy                           0.70      6269\n",
      "   macro avg       0.70      0.70      0.69      6269\n",
      "weighted avg       0.70      0.70      0.69      6269\n",
      "\n",
      "\n",
      "Algorithm: AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      3132\n",
      "           1       0.63      0.62      0.62      3137\n",
      "\n",
      "    accuracy                           0.62      6269\n",
      "   macro avg       0.62      0.62      0.62      6269\n",
      "weighted avg       0.62      0.62      0.62      6269\n",
      "\n",
      "\n",
      "Algorithm: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69      3132\n",
      "           1       0.69      0.67      0.68      3137\n",
      "\n",
      "    accuracy                           0.69      6269\n",
      "   macro avg       0.69      0.69      0.69      6269\n",
      "weighted avg       0.69      0.69      0.69      6269\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(X_test, Y_test, [dt, bagged_dt, boosted_dt, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primo Test con k-Nearest-Neighbor Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def kNN_fun(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    for k in range(1,30):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(X_train,Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(X_test)\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_fun(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otteniamo al più una precisione del 64% con k = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kNN_fun_MinMaxScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )\n",
    "\n",
    "def kNN_fun_StandardScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN MinMax Scaler\n",
      "k: 1  | Accuracy: 0.5844818785094436\n",
      "k: 2  | Accuracy: 0.5793772332822869\n",
      "k: 3  | Accuracy: 0.5972434915773354\n",
      "k: 4  | Accuracy: 0.5935426237876468\n",
      "k: 5  | Accuracy: 0.6010719754977029\n",
      "k: 6  | Accuracy: 0.6004338948443083\n",
      "k: 7  | Accuracy: 0.6027309851965288\n",
      "k: 8  | Accuracy: 0.5957120980091883\n",
      "k: 9  | Accuracy: 0.6033690658499234\n",
      "k: 10  | Accuracy: 0.6004338948443083\n",
      "k: 11  | Accuracy: 0.6047728432873916\n",
      "k: 12  | Accuracy: 0.6027309851965288\n",
      "k: 13  | Accuracy: 0.6092394078611536\n",
      "k: 14  | Accuracy: 0.6063042368555386\n",
      "k: 15  | Accuracy: 0.6126850433894845\n",
      "k: 16  | Accuracy: 0.6074527820316488\n",
      "k: 17  | Accuracy: 0.6123021949974476\n",
      "k: 18  | Accuracy: 0.6108984175599795\n",
      "k: 19  | Accuracy: 0.6097498723838694\n",
      "kNN Standard Scaler\n",
      "k: 1  | Accuracy: 0.5960949464012251\n",
      "k: 2  | Accuracy: 0.5950740173557938\n",
      "k: 3  | Accuracy: 0.6230219499744768\n",
      "k: 4  | Accuracy: 0.6145992853496682\n",
      "k: 5  | Accuracy: 0.6360387953037264\n",
      "k: 6  | Accuracy: 0.6282542113323124\n",
      "k: 7  | Accuracy: 0.6360387953037264\n",
      "k: 8  | Accuracy: 0.635145482388974\n",
      "k: 9  | Accuracy: 0.6385911179173047\n",
      "k: 10  | Accuracy: 0.6391015824400205\n",
      "k: 11  | Accuracy: 0.6411434405308831\n",
      "k: 12  | Accuracy: 0.6387187340479836\n",
      "k: 13  | Accuracy: 0.6493108728943339\n",
      "k: 14  | Accuracy: 0.6480347115875447\n",
      "k: 15  | Accuracy: 0.6486727922409392\n",
      "k: 16  | Accuracy: 0.6488004083716181\n",
      "k: 17  | Accuracy: 0.6498213374170495\n",
      "k: 18  | Accuracy: 0.6503318019397651\n",
      "k: 19  | Accuracy: 0.6569678407350689\n"
     ]
    }
   ],
   "source": [
    "print (\"kNN MinMax Scaler\")\n",
    "kNN_fun_MinMaxScaler(data, labels)\n",
    "print (\"kNN Standard Scaler\")\n",
    "kNN_fun_StandardScaler(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test size : 0.25\n",
    "### Con kNN MinMax Scaler non andiamo oltre il 61%\n",
    "### Con kNN Standard Scaler abbiamo risultati migliori ma comunque non superiamo il 66%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
