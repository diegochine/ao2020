{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open 2020: Winner Predictor\n",
    "## Diego Chinellato - 867637\n",
    "## Giorgia Campardo - 867928\n",
    "### Web Intelligence Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vedere light gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext = pd.read_excel('2019+.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.read_csv('playersdata.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23634 entries, 0 to 23633\n",
      "Data columns (total 42 columns):\n",
      "ATP           23634 non-null int64\n",
      "Location      23634 non-null object\n",
      "Tournament    23634 non-null object\n",
      "Date          23634 non-null datetime64[ns]\n",
      "Series        23634 non-null object\n",
      "Court         23634 non-null object\n",
      "Surface       23634 non-null object\n",
      "Round         23634 non-null object\n",
      "Best of       23634 non-null int64\n",
      "Winner        23634 non-null object\n",
      "Loser         23634 non-null object\n",
      "WRank         23624 non-null float64\n",
      "LRank         23586 non-null float64\n",
      "WPts          23626 non-null float64\n",
      "LPts          23587 non-null float64\n",
      "W1            23483 non-null float64\n",
      "L1            23485 non-null float64\n",
      "W2            23260 non-null float64\n",
      "L2            23260 non-null float64\n",
      "W3            11173 non-null float64\n",
      "L3            11173 non-null float64\n",
      "W4            2200 non-null float64\n",
      "L4            2200 non-null float64\n",
      "W5            816 non-null float64\n",
      "L5            816 non-null float64\n",
      "Wsets         23482 non-null float64\n",
      "Lsets         23480 non-null float64\n",
      "Comment       23634 non-null object\n",
      "B365W         23540 non-null float64\n",
      "B365L         23561 non-null float64\n",
      "EXW           20834 non-null object\n",
      "EXL           20839 non-null float64\n",
      "LBW           20172 non-null float64\n",
      "LBL           20183 non-null float64\n",
      "PSW           23513 non-null float64\n",
      "PSL           23513 non-null float64\n",
      "SJW           10314 non-null float64\n",
      "SJL           10321 non-null float64\n",
      "MaxW          23609 non-null float64\n",
      "MaxL          23609 non-null float64\n",
      "AvgW          23609 non-null float64\n",
      "AvgL          23609 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(29), int64(2), object(10)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ext.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Elo</th>\n",
       "      <th>HardRaw</th>\n",
       "      <th>ClayRaw</th>\n",
       "      <th>GrassRaw</th>\n",
       "      <th>hElo</th>\n",
       "      <th>cElo</th>\n",
       "      <th>gElo</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>Hand</th>\n",
       "      <th>BackHand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rafael Nadal</td>\n",
       "      <td>2203.4</td>\n",
       "      <td>2047.1</td>\n",
       "      <td>2123.6</td>\n",
       "      <td>1676.2</td>\n",
       "      <td>2125.2</td>\n",
       "      <td>2163.5</td>\n",
       "      <td>1939.8</td>\n",
       "      <td>1986-06-03</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>2201.3</td>\n",
       "      <td>2083.4</td>\n",
       "      <td>2062.6</td>\n",
       "      <td>2011.5</td>\n",
       "      <td>2142.4</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>2106.4</td>\n",
       "      <td>1987-05-22</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>2167.3</td>\n",
       "      <td>2047.1</td>\n",
       "      <td>1824.6</td>\n",
       "      <td>1930.6</td>\n",
       "      <td>2107.2</td>\n",
       "      <td>1995.9</td>\n",
       "      <td>2048.9</td>\n",
       "      <td>1981-08-08</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stefanos Tsitsipas</td>\n",
       "      <td>2067.4</td>\n",
       "      <td>1980.4</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1526.3</td>\n",
       "      <td>2023.9</td>\n",
       "      <td>1991.2</td>\n",
       "      <td>1796.9</td>\n",
       "      <td>1998-08-12</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dominic Thiem</td>\n",
       "      <td>2066.2</td>\n",
       "      <td>1941.5</td>\n",
       "      <td>2030.7</td>\n",
       "      <td>1602.1</td>\n",
       "      <td>2003.9</td>\n",
       "      <td>2048.5</td>\n",
       "      <td>1834.2</td>\n",
       "      <td>1993-09-03</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank              Player     Elo  HardRaw ClayRaw GrassRaw    hElo    cElo  \\\n",
       "0     1        Rafael Nadal  2203.4   2047.1  2123.6   1676.2  2125.2  2163.5   \n",
       "1     2      Novak Djokovic  2201.3   2083.4  2062.6   2011.5  2142.4  2132.0   \n",
       "2     3       Roger Federer  2167.3   2047.1  1824.6   1930.6  2107.2  1995.9   \n",
       "3     4  Stefanos Tsitsipas  2067.4   1980.4  1915.0   1526.3  2023.9  1991.2   \n",
       "4     5       Dominic Thiem  2066.2   1941.5  2030.7   1602.1  2003.9  2048.5   \n",
       "\n",
       "     gElo   BirthDate Hand BackHand  \n",
       "0  1939.8  1986-06-03    L        2  \n",
       "1  2106.4  1987-05-22    R        2  \n",
       "2  2048.9  1981-08-08    R        1  \n",
       "3  1796.9  1998-08-12    R        1  \n",
       "4  1834.2  1993-09-03    R        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elo_rankings(data):\n",
    "    \"\"\"\n",
    "    Given the list on matches in chronological order, for each match, computes \n",
    "    the elo ranking of the 2 players at the beginning of the match\n",
    "    \"\"\"\n",
    "    print(\"Elo rankings computing...\")\n",
    "    players=list(pd.Series(list(data.Winner)+list(data.Loser)).value_counts().index)\n",
    "    elo=pd.Series(np.ones(len(players))*1500,index=players)\n",
    "    ranking_elo=[(1500,1500)]\n",
    "    for i in range(1,len(data)):\n",
    "        w=data.iloc[i-1,:].Winner\n",
    "        l=data.iloc[i-1,:].Loser\n",
    "        elow=elo[w]\n",
    "        elol=elo[l]\n",
    "        pwin=1 / (1 + 10 ** ((elol - elow) / 400))    \n",
    "        K_win=32\n",
    "        K_los=32\n",
    "        new_elow=elow+K_win*(1-pwin)\n",
    "        new_elol=elol-K_los*(1-pwin)\n",
    "        elo[w]=new_elow\n",
    "        elo[l]=new_elol\n",
    "        ranking_elo.append((elo[data.iloc[i,:].Winner],elo[data.iloc[i,:].Loser])) \n",
    "    ranking_elo=pd.DataFrame(ranking_elo,columns=[\"elo_winner\",\"elo_loser\"])    \n",
    "    ranking_elo[\"proba_elo\"]=1 / (1 + 10 ** ((ranking_elo[\"elo_loser\"] - ranking_elo[\"elo_winner\"]) / 400))   \n",
    "    return ranking_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_datasets(base, scraped):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df,\n",
    "                    max_date=2014,\n",
    "                    features_to_drop=[], \n",
    "                    missing_values=\"drop\", \n",
    "                    drop_first=False):\n",
    "    \"\"\"\n",
    "    Processes raw data and returns a tuple (X, Y) where X is the cleaned dataset and Y is the array of labels.\n",
    "    \"\"\"\n",
    "    # Sort by date to calculate ELO\n",
    "    X = df.sort_values(by='Date')\n",
    "    \n",
    "    # Drop old data\n",
    "    X = X.drop(index=X[X['Date'] < pd.Timestamp(max_date, 1, 1)].index)\n",
    "    \n",
    "    # Drop unuseful columns\n",
    "    features_to_drop += ['ATP', 'Location', 'Tournament', 'Date', 'Comment', \n",
    "                         'WPts', 'LPts', 'Wsets', 'Lsets', \n",
    "                         'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', \n",
    "                         'B365W', 'B365L', 'EXW', 'EXL', 'LBW', 'LBL', 'PSW', 'PSL', 'SJW', 'SJL']\n",
    "    X = X.drop(columns=features_to_drop)\n",
    "    \n",
    "    # Deal with missing values\n",
    "    X['WRank'] = X['WRank'].fillna(value=X['WRank'].max()+100).astype(int)\n",
    "    X['LRank'] = X['LRank'].fillna(value=X['LRank'].max()+100).astype(int)\n",
    "    \n",
    "    if missing_values == 'drop':\n",
    "        X = X.dropna()\n",
    "    elif missing_values == 'custom':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Wrong parameter: missing_values')\n",
    "\n",
    "    # Convert ordinal features to int (higher value means more important)\n",
    "    series = ['ATP250', 'ATP500', 'Masters 1000', 'Masters Cup', 'Grand Slam']\n",
    "    series2int = {s: i for i, s in enumerate(series)}\n",
    "    rounds2int = {'1st Round': 0,\n",
    "                  '2nd Round': 1,\n",
    "                  '3rd Round': 2,\n",
    "                  '4th Round': 3,\n",
    "                  'Round Robin': 4,\n",
    "                  'Quarterfinals': 5,\n",
    "                  'Semifinals': 6,\n",
    "                  'The Final': 7,\n",
    "                 }\n",
    "    X = X.replace({'Round': rounds2int, 'Series': series2int})\n",
    "    \n",
    "    # Convert court to binary\n",
    "    X = X.replace({'Court': {'Outdoor': 0, 'Indoor': 1}})\n",
    "    \n",
    "    # One hot encode categorical features into binary features\n",
    "    X = pd.get_dummies(X, prefix=['Surface_'], columns=['Surface'], drop_first=drop_first)\n",
    "    \n",
    "    # Convert players to numeric ?\n",
    "    players = set(X['Winner']) | set(X['Loser'])\n",
    "    players_to_id = {}\n",
    "    for i, player in enumerate(players):\n",
    "        players_to_id[player] = i\n",
    "    X = X.replace({'Winner': players_to_id, 'Loser': players_to_id})\n",
    "    X = X.astype({'Winner':int, 'Loser':int})\n",
    "\n",
    "    X = X.rename(columns={'Winner':'1st Player', 'Loser':'2nd Player', \n",
    "                          'WRank':'P1Rank', 'LRank':'P2Rank', \n",
    "                          'MaxW':'MaxP1', 'MaxL':'MaxP2', \n",
    "                          'AvgW':'AvgP1', 'AvgL':'AvgP2'})\n",
    "    \n",
    "    # Generate labels\n",
    "    Y = np.concatenate([np.ones(X.shape[0], dtype=int), np.zeros(X.shape[0], dtype=int)])\n",
    "    # Swap columns and concatenate to data\n",
    "    tmp = X.copy()\n",
    "    cols_to_swap = ['1st Player', '2nd Player', 'P1Rank', 'P2Rank', 'MaxP1', 'MaxP2',  'AvgP1',  'AvgP2']\n",
    "    cols_swapped = ['2nd Player', '1st Player', 'P2Rank', 'P1Rank', 'MaxP2', 'MaxP1',  'AvgP2',  'AvgP1']\n",
    "    tmp[cols_to_swap] = tmp[cols_swapped]\n",
    "    tmp.index = np.array(range(X.shape[0] + 1, X.shape[0] * 2 + 1))\n",
    "    X = pd.concat((X, tmp))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = preprocess_data(df_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train set, validation set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.20)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    # Builds a decision tree and performs automatic hyper-parameters tuning\n",
    "    scores = []\n",
    "    for criterion in ('gini', 'entropy'):\n",
    "        for depth in range(5, 50):\n",
    "            for leaves in range(5, 20):\n",
    "                dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                            criterion=criterion,\n",
    "                                            max_depth=depth)\n",
    "                dt.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=dt.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, criterion, depth, leaves)]\n",
    "    best = max(scores)\n",
    "    acc, criterion, depth, leaves = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('Criterion:', criterion)\n",
    "    print('Max depth:', depth)\n",
    "    print('Max leaves:', leaves)\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                     criterion=criterion,\n",
    "                                     max_depth=depth)\n",
    "    dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bagging_classifier(X_train, Y_train, X_valid, Y_valid, dt_params):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    scores = []\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=dt_params[3],\n",
    "                                criterion=dt_params[1],\n",
    "                                max_depth=dt_params[2])\n",
    "    for bootstrap in (True, False):\n",
    "        for n_est in range(10, 201, 20):\n",
    "            for max_samples in (0.25, 0.50, 0.75, 1.0):\n",
    "                bagged_dt = BaggingClassifier(dt, bootstrap=bootstrap,\n",
    "                                              n_estimators=n_est,\n",
    "                                              max_samples=max_samples,\n",
    "                                              n_jobs=-1)\n",
    "                bagged_dt.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=bagged_dt.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, bootstrap, n_est, max_samples)]\n",
    "    best = max(scores)\n",
    "    acc, bootsrap, n_est, max_samples = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('Boostrap:', bootsrap)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Max samples:', max_samples)\n",
    "    bagged_dt = BaggingClassifier(dt, \n",
    "                                  bootstrap=bootstrap,\n",
    "                                  n_estimators=n_est, \n",
    "                                  max_samples=max_samples)\n",
    "    bagged_dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return bagged_dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adaboost(X_train, Y_train, X_valid, Y_valid, dt_params):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    scores = []\n",
    "    dt = DecisionTreeClassifier(max_leaf_nodes=dt_params[3],\n",
    "                                criterion=dt_params[1],\n",
    "                                max_depth=dt_params[2])\n",
    "    for n_est in range(50, 301, 25):\n",
    "        for learning_rate in (0.50, 0.75, 1.0, 1.5):\n",
    "            boosted_dt = AdaBoostClassifier(dt,\n",
    "                                            n_estimators=n_est,\n",
    "                                            learning_rate=learning_rate)\n",
    "            boosted_dt.fit(X_train, Y_train)\n",
    "            valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=bagged_dt.predict(X_valid)), 3)\n",
    "            scores += [(valid_acc, n_est, learning_rate)]\n",
    "    best = max(scores)\n",
    "    acc, n_est, learning_rate = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Learning rate:', learning_rate)\n",
    "    boosted_dt = AdaBoostClassifier(dt,\n",
    "                                    n_estimators=n_est,\n",
    "                                    learning_rate=learning_rate)\n",
    "    boosted_dt.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return boosted_dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_forest(X_train, Y_train, X_valid, Y_valid):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    scores = []\n",
    "    for n_est in range(50, 301, 25):\n",
    "        for criterion in ('gini', 'entropy'):\n",
    "            for bootstrap in (True, False):\n",
    "                rf = RandomForestClassifier(n_estimators=n_est,\n",
    "                                               bootstrap=bootstrap,\n",
    "                                               criterion=criterion,\n",
    "                                               n_jobs=-1)\n",
    "                rf.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=rf.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, n_est, criterion, bootstrap)]\n",
    "    best = max(scores)\n",
    "    acc, n_est, criterion, bootstrap = best\n",
    "    print('Max accuracy on validation set:', acc)\n",
    "    print('N. estimators:', n_est)\n",
    "    print('Criterion:', criterion)\n",
    "    print('Bootstrap:', bootstrap)\n",
    "    rf = RandomForestClassifier(n_estimators=n_est,\n",
    "                               bootstrap=bootstrap,\n",
    "                               criterion=criterion,\n",
    "                               n_jobs=-1)\n",
    "    rf.fit(pd.concat([X_train, X_valid]), np.concatenate([Y_train, Y_valid]))\n",
    "    return rf, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.695\n",
      "Criterion: gini\n",
      "Max depth: 6\n",
      "Max leaves: 19\n"
     ]
    }
   ],
   "source": [
    "dt, dt_params = build_decision_tree(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.695\n",
      "Boostrap: True\n",
      "N. estimators: 100\n",
      "Max samples: 0.5\n"
     ]
    }
   ],
   "source": [
    "bagged_dt, bagged_params = build_bagging_classifier(X_train, Y_train, X_valid, Y_valid, dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.695\n",
      "N. estimators: 300\n",
      "Learning rate: 1.5\n"
     ]
    }
   ],
   "source": [
    "boosted_dt, boosted_params = build_adaboost(X_train, Y_train, X_valid, Y_valid, dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy on validation set: 0.687\n",
      "N. estimators: 225\n",
      "Criterion: gini\n",
      "Bootstrap: True\n"
     ]
    }
   ],
   "source": [
    "rf, rf_params = build_random_forest(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(X, Y, models):\n",
    "    for model in models:\n",
    "        print('Algorithm:', str(type(model)).split('.')[-1][:-2])\n",
    "        rep = classification_report(y_true=Y, y_pred=model.predict(X))\n",
    "        print(rep)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68      3132\n",
      "           1       0.68      0.72      0.70      3137\n",
      "\n",
      "    accuracy                           0.69      6269\n",
      "   macro avg       0.69      0.69      0.69      6269\n",
      "weighted avg       0.69      0.69      0.69      6269\n",
      "\n",
      "\n",
      "Algorithm: BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3132\n",
      "           1       0.70      0.68      0.69      3137\n",
      "\n",
      "    accuracy                           0.70      6269\n",
      "   macro avg       0.70      0.70      0.69      6269\n",
      "weighted avg       0.70      0.70      0.69      6269\n",
      "\n",
      "\n",
      "Algorithm: AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      3132\n",
      "           1       0.63      0.62      0.62      3137\n",
      "\n",
      "    accuracy                           0.62      6269\n",
      "   macro avg       0.62      0.62      0.62      6269\n",
      "weighted avg       0.62      0.62      0.62      6269\n",
      "\n",
      "\n",
      "Algorithm: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69      3132\n",
      "           1       0.69      0.67      0.68      3137\n",
      "\n",
      "    accuracy                           0.69      6269\n",
      "   macro avg       0.69      0.69      0.69      6269\n",
      "weighted avg       0.69      0.69      0.69      6269\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(X_test, Y_test, [dt, bagged_dt, boosted_dt, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primo Test con k-Nearest-Neighbor Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def kNN_fun(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    for k in range(1,30):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(X_train,Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(X_test)\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_fun(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otteniamo al più una precisione del 64% con k = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kNN_fun_MinMaxScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )\n",
    "\n",
    "def kNN_fun_StandardScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN MinMax Scaler\n",
      "k: 1  | Accuracy: 0.5844818785094436\n",
      "k: 2  | Accuracy: 0.5793772332822869\n",
      "k: 3  | Accuracy: 0.5972434915773354\n",
      "k: 4  | Accuracy: 0.5935426237876468\n",
      "k: 5  | Accuracy: 0.6010719754977029\n",
      "k: 6  | Accuracy: 0.6004338948443083\n",
      "k: 7  | Accuracy: 0.6027309851965288\n",
      "k: 8  | Accuracy: 0.5957120980091883\n",
      "k: 9  | Accuracy: 0.6033690658499234\n",
      "k: 10  | Accuracy: 0.6004338948443083\n",
      "k: 11  | Accuracy: 0.6047728432873916\n",
      "k: 12  | Accuracy: 0.6027309851965288\n",
      "k: 13  | Accuracy: 0.6092394078611536\n",
      "k: 14  | Accuracy: 0.6063042368555386\n",
      "k: 15  | Accuracy: 0.6126850433894845\n",
      "k: 16  | Accuracy: 0.6074527820316488\n",
      "k: 17  | Accuracy: 0.6123021949974476\n",
      "k: 18  | Accuracy: 0.6108984175599795\n",
      "k: 19  | Accuracy: 0.6097498723838694\n",
      "kNN Standard Scaler\n",
      "k: 1  | Accuracy: 0.5960949464012251\n",
      "k: 2  | Accuracy: 0.5950740173557938\n",
      "k: 3  | Accuracy: 0.6230219499744768\n",
      "k: 4  | Accuracy: 0.6145992853496682\n",
      "k: 5  | Accuracy: 0.6360387953037264\n",
      "k: 6  | Accuracy: 0.6282542113323124\n",
      "k: 7  | Accuracy: 0.6360387953037264\n",
      "k: 8  | Accuracy: 0.635145482388974\n",
      "k: 9  | Accuracy: 0.6385911179173047\n",
      "k: 10  | Accuracy: 0.6391015824400205\n",
      "k: 11  | Accuracy: 0.6411434405308831\n",
      "k: 12  | Accuracy: 0.6387187340479836\n",
      "k: 13  | Accuracy: 0.6493108728943339\n",
      "k: 14  | Accuracy: 0.6480347115875447\n",
      "k: 15  | Accuracy: 0.6486727922409392\n",
      "k: 16  | Accuracy: 0.6488004083716181\n",
      "k: 17  | Accuracy: 0.6498213374170495\n",
      "k: 18  | Accuracy: 0.6503318019397651\n",
      "k: 19  | Accuracy: 0.6569678407350689\n"
     ]
    }
   ],
   "source": [
    "print (\"kNN MinMax Scaler\")\n",
    "kNN_fun_MinMaxScaler(data, labels)\n",
    "print (\"kNN Standard Scaler\")\n",
    "kNN_fun_StandardScaler(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test size : 0.25\n",
    "### Con kNN MinMax Scaler non andiamo oltre il 61%\n",
    "### Con kNN Standard Scaler abbiamo risultati migliori ma comunque non superiamo il 66%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
