{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open 2020: Winner Predictor\n",
    "## Diego Chinellato - 867637\n",
    "## Giorgia Campardo - 867928\n",
    "### Web Intelligence Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vedere light gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext = pd.read_excel('2019+.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23634 entries, 0 to 23633\n",
      "Data columns (total 42 columns):\n",
      "ATP           23634 non-null int64\n",
      "Location      23634 non-null object\n",
      "Tournament    23634 non-null object\n",
      "Date          23634 non-null datetime64[ns]\n",
      "Series        23634 non-null object\n",
      "Court         23634 non-null object\n",
      "Surface       23634 non-null object\n",
      "Round         23634 non-null object\n",
      "Best of       23634 non-null int64\n",
      "Winner        23634 non-null object\n",
      "Loser         23634 non-null object\n",
      "WRank         23624 non-null float64\n",
      "LRank         23586 non-null float64\n",
      "WPts          23626 non-null float64\n",
      "LPts          23587 non-null float64\n",
      "W1            23483 non-null float64\n",
      "L1            23485 non-null float64\n",
      "W2            23260 non-null float64\n",
      "L2            23260 non-null float64\n",
      "W3            11173 non-null float64\n",
      "L3            11173 non-null float64\n",
      "W4            2200 non-null float64\n",
      "L4            2200 non-null float64\n",
      "W5            816 non-null float64\n",
      "L5            816 non-null float64\n",
      "Wsets         23482 non-null float64\n",
      "Lsets         23480 non-null float64\n",
      "Comment       23634 non-null object\n",
      "B365W         23540 non-null float64\n",
      "B365L         23561 non-null float64\n",
      "EXW           20834 non-null object\n",
      "EXL           20839 non-null float64\n",
      "LBW           20172 non-null float64\n",
      "LBL           20183 non-null float64\n",
      "PSW           23513 non-null float64\n",
      "PSL           23513 non-null float64\n",
      "SJW           10314 non-null float64\n",
      "SJL           10321 non-null float64\n",
      "MaxW          23609 non-null float64\n",
      "MaxL          23609 non-null float64\n",
      "AvgW          23609 non-null float64\n",
      "AvgL          23609 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(29), int64(2), object(10)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ext.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  135,   136,   137,   138,   139,   140,   141,   142,   143,\n",
       "              144,\n",
       "            ...\n",
       "            23470, 23471, 23472, 23473, 23474, 23475, 23476, 23477, 23478,\n",
       "            23479],\n",
       "           dtype='int64', length=7953)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ext[df_ext['Date'] < pd.Timestamp(2014, 1, 1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elo_rankings(data):\n",
    "    \"\"\"\n",
    "    Given the list on matches in chronological order, for each match, computes \n",
    "    the elo ranking of the 2 players at the beginning of the match\n",
    "    \"\"\"\n",
    "    print(\"Elo rankings computing...\")\n",
    "    players=list(pd.Series(list(data.Winner)+list(data.Loser)).value_counts().index)\n",
    "    elo=pd.Series(np.ones(len(players))*1500,index=players)\n",
    "    ranking_elo=[(1500,1500)]\n",
    "    for i in range(1,len(data)):\n",
    "        w=data.iloc[i-1,:].Winner\n",
    "        l=data.iloc[i-1,:].Loser\n",
    "        elow=elo[w]\n",
    "        elol=elo[l]\n",
    "        pwin=1 / (1 + 10 ** ((elol - elow) / 400))    \n",
    "        K_win=32\n",
    "        K_los=32\n",
    "        new_elow=elow+K_win*(1-pwin)\n",
    "        new_elol=elol-K_los*(1-pwin)\n",
    "        elo[w]=new_elow\n",
    "        elo[l]=new_elol\n",
    "        ranking_elo.append((elo[data.iloc[i,:].Winner],elo[data.iloc[i,:].Loser])) \n",
    "    ranking_elo=pd.DataFrame(ranking_elo,columns=[\"elo_winner\",\"elo_loser\"])    \n",
    "    ranking_elo[\"proba_elo\"]=1 / (1 + 10 ** ((ranking_elo[\"elo_loser\"] - ranking_elo[\"elo_winner\"]) / 400))   \n",
    "    return ranking_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df,\n",
    "                    max_date=2014,\n",
    "                    features_to_drop=[], \n",
    "                    missing_values=\"drop\", \n",
    "                    drop_first=False):\n",
    "    \"\"\"\n",
    "    Processes raw data and returns a tuple (X, Y) where X is the cleaned dataset and Y is the array of labels.\n",
    "    \"\"\"\n",
    "    # Sort by date to calculate ELO\n",
    "    X = df.sort_values(by='Date')\n",
    "    \n",
    "    # Drop old data\n",
    "    X = X.drop(index=X[X['Date'] < pd.Timestamp(max_date, 1, 1)].index)\n",
    "    \n",
    "    # Drop unuseful columns\n",
    "    features_to_drop += ['ATP', 'Location', 'Tournament', 'Date', 'Comment', \n",
    "                         'WPts', 'LPts', 'Wsets', 'Lsets', \n",
    "                         'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', \n",
    "                         'B365W', 'B365L', 'EXW', 'EXL', 'LBW', 'LBL', 'PSW', 'PSL', 'SJW', 'SJL']\n",
    "    X = X.drop(columns=features_to_drop)\n",
    "    \n",
    "    # Deal with missing values\n",
    "    X['WRank'] = X['WRank'].fillna(value=X['WRank'].max()+1).astype(int)\n",
    "    X['LRank'] = X['LRank'].fillna(value=X['LRank'].max()+1).astype(int)\n",
    "    \n",
    "    if missing_values == 'drop':\n",
    "        X = X.dropna()\n",
    "    elif missing_values == 'mean':\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        pass\n",
    "    elif missing_values == 'custom':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Wrong parameter: missing_values')\n",
    "\n",
    "    # Convert ordinal features to int (higher value means more important)\n",
    "    series = ['ATP250', 'ATP500', 'Masters 1000', 'Masters Cup', 'Grand Slam']\n",
    "    series2int = {s: i for i, s in enumerate(series)}\n",
    "    rounds2int = {'1st Round': 0,\n",
    "                  '2nd Round': 1,\n",
    "                  '3rd Round': 2,\n",
    "                  '4th Round': 3,\n",
    "                  'Round Robin': 4,\n",
    "                  'Quarterfinals': 5,\n",
    "                  'Semifinals': 6,\n",
    "                  'The Final': 7,\n",
    "                 }\n",
    "    X = X.replace({'Round': rounds2int, 'Series': series2int})\n",
    "    \n",
    "    # Convert court to binary\n",
    "    X = X.replace({'Court': {'Outdoor': 0, 'Indoor': 1}})\n",
    "    \n",
    "    # One hot encode categorical features into binary features\n",
    "    X = pd.get_dummies(X, prefix=['Surface_'], columns=['Surface'], drop_first=drop_first)\n",
    "    \n",
    "    # Convert players to numeric ?\n",
    "    players = set(X['Winner']) | set(X['Loser'])\n",
    "    players_to_id = {}\n",
    "    for i, player in enumerate(players):\n",
    "        players_to_id[player] = i\n",
    "    X = X.replace({'Winner': players_to_id, 'Loser': players_to_id})\n",
    "    X = X.astype({'Winner':int, 'Loser':int})\n",
    "\n",
    "    X = X.rename(columns={'Winner':'1st Player', 'Loser':'2nd Player', \n",
    "                          'WRank':'P1Rank', 'LRank':'P2Rank', \n",
    "                          'MaxW':'MaxP1', 'MaxL':'MaxP2', \n",
    "                          'AvgW':'AvgP1', 'AvgL':'AvgP2'})\n",
    "    \n",
    "    # Generate labels\n",
    "    Y = np.concatenate([np.ones(X.shape[0], dtype=int), np.zeros(X.shape[0], dtype=int)])\n",
    "    # Swap columns and concatenate to data\n",
    "    tmp = X.copy()\n",
    "    cols_to_swap = ['1st Player', '2nd Player', 'P1Rank', 'P2Rank', 'MaxP1', 'MaxP2',  'AvgP1',  'AvgP2']\n",
    "    cols_swapped = ['2nd Player', '1st Player', 'P2Rank', 'P1Rank', 'MaxP2', 'MaxP1',  'AvgP2',  'AvgP1']\n",
    "    tmp[cols_to_swap] = tmp[cols_swapped]\n",
    "    tmp.index = np.array(range(X.shape[0] + 1, X.shape[0] * 2 + 1))\n",
    "    X = pd.concat((X, tmp))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = preprocess_data(df_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train set, validation set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.20)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(X_train, Y_train, X_valid, Y_valid):\n",
    "    # This function builds a decision tree and performs automatic hyper-parameters tuning\n",
    "    scores = []\n",
    "    for criterion in ('gini', 'entropy'):\n",
    "        for depth in range(5, 50):\n",
    "            for leaves in range(5, 20):\n",
    "                dt = tree.DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                                 criterion=criterion,\n",
    "                                                 max_depth=depth)\n",
    "                dt.fit(X_train, Y_train)\n",
    "                valid_acc = round(accuracy_score(y_true=Y_valid, y_pred=dt.predict(X_valid)), 3)\n",
    "                scores += [(valid_acc, criterion, depth, leaves)]\n",
    "    best = max(scores)\n",
    "    print(best)\n",
    "    acc, criterion, depth, leaves = best\n",
    "    dt = tree.DecisionTreeClassifier(max_leaf_nodes=leaves,\n",
    "                                     criterion=criterion,\n",
    "                                     max_depth=depth)\n",
    "    dt.fit(X_train, Y_train)\n",
    "    return dt, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69758, 'gini', 49, 13)\n"
     ]
    }
   ],
   "source": [
    "dt, params = build_decision_tree(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primo Test con k-Nearest-Neighbor Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def kNN_fun(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    for k in range(1,30):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(X_train,Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(X_test)\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1  | Accuracy: 0.5758039816232772\n",
      "k: 2  | Accuracy: 0.5678917815211842\n",
      "k: 3  | Accuracy: 0.597753956100051\n",
      "k: 4  | Accuracy: 0.59315977539561\n",
      "k: 5  | Accuracy: 0.6089841755997958\n",
      "k: 6  | Accuracy: 0.6086013272077591\n",
      "k: 7  | Accuracy: 0.6126850433894845\n",
      "k: 8  | Accuracy: 0.613323124042879\n",
      "k: 9  | Accuracy: 0.622766717713119\n",
      "k: 10  | Accuracy: 0.6177896886166412\n",
      "k: 11  | Accuracy: 0.6294027565084227\n",
      "k: 12  | Accuracy: 0.6230219499744768\n",
      "k: 13  | Accuracy: 0.6271056661562021\n",
      "k: 14  | Accuracy: 0.6237876467585503\n",
      "k: 15  | Accuracy: 0.6282542113323124\n",
      "k: 16  | Accuracy: 0.6248085758039816\n",
      "k: 17  | Accuracy: 0.6332312404287902\n",
      "k: 18  | Accuracy: 0.6309341500765697\n",
      "k: 19  | Accuracy: 0.6339969372128637\n",
      "k: 20  | Accuracy: 0.6354007146503318\n",
      "k: 21  | Accuracy: 0.6383358856559469\n",
      "k: 22  | Accuracy: 0.6373149566105155\n",
      "k: 23  | Accuracy: 0.6385911179173047\n",
      "k: 24  | Accuracy: 0.6387187340479836\n",
      "k: 25  | Accuracy: 0.6406329760081675\n",
      "k: 26  | Accuracy: 0.6406329760081675\n",
      "k: 27  | Accuracy: 0.6391015824400205\n",
      "k: 28  | Accuracy: 0.6389739663093414\n",
      "k: 29  | Accuracy: 0.6424196018376723\n"
     ]
    }
   ],
   "source": [
    "kNN_fun(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otteniamo al più una precisione del 64% con k = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kNN_fun_MinMaxScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )\n",
    "\n",
    "def kNN_fun_StandardScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN MinMax Scaler\n",
      "k: 1  | Accuracy: 0.5844818785094436\n",
      "k: 2  | Accuracy: 0.5793772332822869\n",
      "k: 3  | Accuracy: 0.5972434915773354\n",
      "k: 4  | Accuracy: 0.5935426237876468\n",
      "k: 5  | Accuracy: 0.6010719754977029\n",
      "k: 6  | Accuracy: 0.6004338948443083\n",
      "k: 7  | Accuracy: 0.6027309851965288\n",
      "k: 8  | Accuracy: 0.5957120980091883\n",
      "k: 9  | Accuracy: 0.6033690658499234\n",
      "k: 10  | Accuracy: 0.6004338948443083\n",
      "k: 11  | Accuracy: 0.6047728432873916\n",
      "k: 12  | Accuracy: 0.6027309851965288\n",
      "k: 13  | Accuracy: 0.6092394078611536\n",
      "k: 14  | Accuracy: 0.6063042368555386\n",
      "k: 15  | Accuracy: 0.6126850433894845\n",
      "k: 16  | Accuracy: 0.6074527820316488\n",
      "k: 17  | Accuracy: 0.6123021949974476\n",
      "k: 18  | Accuracy: 0.6108984175599795\n",
      "k: 19  | Accuracy: 0.6097498723838694\n",
      "kNN Standard Scaler\n",
      "k: 1  | Accuracy: 0.5960949464012251\n",
      "k: 2  | Accuracy: 0.5950740173557938\n",
      "k: 3  | Accuracy: 0.6230219499744768\n",
      "k: 4  | Accuracy: 0.6145992853496682\n",
      "k: 5  | Accuracy: 0.6360387953037264\n",
      "k: 6  | Accuracy: 0.6282542113323124\n",
      "k: 7  | Accuracy: 0.6360387953037264\n",
      "k: 8  | Accuracy: 0.635145482388974\n",
      "k: 9  | Accuracy: 0.6385911179173047\n",
      "k: 10  | Accuracy: 0.6391015824400205\n",
      "k: 11  | Accuracy: 0.6411434405308831\n",
      "k: 12  | Accuracy: 0.6387187340479836\n",
      "k: 13  | Accuracy: 0.6493108728943339\n",
      "k: 14  | Accuracy: 0.6480347115875447\n",
      "k: 15  | Accuracy: 0.6486727922409392\n",
      "k: 16  | Accuracy: 0.6488004083716181\n",
      "k: 17  | Accuracy: 0.6498213374170495\n",
      "k: 18  | Accuracy: 0.6503318019397651\n",
      "k: 19  | Accuracy: 0.6569678407350689\n"
     ]
    }
   ],
   "source": [
    "print (\"kNN MinMax Scaler\")\n",
    "kNN_fun_MinMaxScaler(data, labels)\n",
    "print (\"kNN Standard Scaler\")\n",
    "kNN_fun_StandardScaler(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test size : 0.33\n",
    "### Con kNN MinMax Scaler non andiamo oltre il 62%\n",
    "### Con kNN Standard Scaler abbiamo risultati migliori ma comunque non superiamo il 66%\n",
    "## Test size : 0.25\n",
    "### Con kNN MinMax Scaler non andiamo oltre il 61%\n",
    "### Con kNN Standard Scaler abbiamo risultati migliori ma comunque non superiamo il 66%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
