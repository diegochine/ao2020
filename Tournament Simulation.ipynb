{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# our modules\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1st Round', '2nd Round', 'Quarterfinals', 'Semifinals',\n",
       "       'The Final'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torneo = pd.read_csv('data/2020.csv', \n",
    "                            encoding='utf-8-sig', \n",
    "                            dtype=DATA_TYPES,\n",
    "                            parse_dates=['Date', 'WBD', 'LBD'])\n",
    "torneo['Round'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='entropy',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=0.76, n_estimators=200, n_jobs=-1,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = ['Best of', 'Court','WElo', 'WSurfElo', 'WHand', 'WBHand',\n",
    "                    'LElo', 'LSurfElo', 'LHand', 'LBHand','Surface']\n",
    "X, Y = preprocess_data(2011, 2019, features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='entropy',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=0.8, n_estimators=200, n_jobs=-1, oob_score=False,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier(criterion='entropy'), \n",
    "                        bootstrap=True,\n",
    "                        n_estimators=200,\n",
    "                        max_samples=0.8,\n",
    "                        n_jobs=-1)    \n",
    "bdt.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(model,\n",
    "               atp = 1, \n",
    "               features_to_drop=[], \n",
    "               missing_values=\"drop\", \n",
    "               drop_first=False):\n",
    "    \n",
    "    tournament = pd.read_csv(\"data/\" + str(2020) + \".csv\", encoding='utf-8-sig', dtype=DATA_TYPES)\n",
    "    tournament = tournament[tournament['ATP'] == atp]\n",
    "    # TODO filtrare per atp e round(primo)\n",
    "    \n",
    "    tournament_to_test = unify_data(tournament, features_to_drop, 'drop', drop_first)\n",
    "    \n",
    "    prediction = model.predict(tournament_to_test[tournament_to_test['Round'] == 0])\n",
    "    accuracy = round(accuracy_score(y_true=np.ones(len(prediction), dtype=int), y_pred=prediction), 3)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    firstR = tournament[tournament['Round'] == '1st Round']\n",
    "    i = 0\n",
    "    for j, match in firstR.iterrows():\n",
    "        print('P1: ' + match['Winner'], 'P2: '+ match['Loser'], 'Wins:', prediction[i])\n",
    "        i+=1\n",
    "\n",
    "    #print(prediction)\n",
    "    \n",
    "    return tournament_to_test, X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75\n",
      "P1: Bublik A. P2: Mannarino A. Wins: 0\n",
      "P1: Moutet C. P2: Sandgren T. Wins: 1\n",
      "P1: Verdasco F. P2: Andujar P. Wins: 1\n",
      "P1: Bedene A. P2: Ymer M. Wins: 1\n",
      "P1: Chardy J. P2: Barrere G. Wins: 1\n",
      "P1: Kecmanovic M. P2: Thompson J. Wins: 1\n",
      "P1: Krajinovic F. P2: Edmund K. Wins: 1\n",
      "P1: Herbert P.H. P2: Cecchinato M. Wins: 0\n",
      "P1: Kukushkin M. P2: Jaziri M. Wins: 0\n",
      "P1: Fucsovics M. P2: Tiafoe F. Wins: 1\n",
      "P1: Djere L. P2: Sonego L. Wins: 1\n",
      "P1: Ilkel C. P2: Berankis R. Wins: 1\n"
     ]
    }
   ],
   "source": [
    "T, X, Y = simulation(bdt, 1, features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series            0\n",
      "Round             0\n",
      "WRank            55\n",
      "LRank            43\n",
      "WPts            919\n",
      "LPts           1111\n",
      "MaxW           2.25\n",
      "MaxL            1.8\n",
      "AvgW           2.11\n",
      "AvgL           1.72\n",
      "WEloCalc       1500\n",
      "LEloCalc       1500\n",
      "GreaterRank       0\n",
      "Name: 0, dtype: object Series            0\n",
      "Round             0\n",
      "WRank            54\n",
      "LRank            83\n",
      "WPts            920\n",
      "LPts            636\n",
      "MaxW           1.57\n",
      "MaxL           2.65\n",
      "AvgW           1.53\n",
      "AvgL           2.47\n",
      "WEloCalc       1500\n",
      "LEloCalc       1500\n",
      "GreaterRank       1\n",
      "Name: 4, dtype: object Series            0\n",
      "Round             0\n",
      "WRank            39\n",
      "LRank            51\n",
      "WPts           1151\n",
      "LPts            990\n",
      "MaxW            3.2\n",
      "MaxL           1.43\n",
      "AvgW           3.03\n",
      "AvgL           1.37\n",
      "WEloCalc       1500\n",
      "LEloCalc       1516\n",
      "GreaterRank       1\n",
      "Name: 12, dtype: object Series            0\n",
      "Round             0\n",
      "WRank            70\n",
      "LRank            47\n",
      "WPts            790\n",
      "LPts           1050\n",
      "MaxW            2.1\n",
      "MaxL           1.87\n",
      "AvgW           2.01\n",
      "AvgL           1.78\n",
      "WEloCalc       1500\n",
      "LEloCalc       1500\n",
      "GreaterRank       0\n",
      "Name: 11, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(T.iloc[0],T.iloc[4], T.iloc[7], T.iloc[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notare che il modello sbaglia la predizione quando anche le scommesse(Max e Avg) sbagliano(era pi√π quotata la vittoria del giocatore che di fatto ha perso)\n",
    "TODO: \n",
    "    - fare un decisore stupido basato sulle scommesse\n",
    "    - provare a tenere B365, nel caso droppare Avg e Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
