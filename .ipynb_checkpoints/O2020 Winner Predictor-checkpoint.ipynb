{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open 2020: Winner Predictor\n",
    "## Diego Chinellato - 867637\n",
    "## Giorgia Campardo - 867928\n",
    "### Web Intelligence Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('2019.xlsx')\n",
    "df_ext = pd.read_excel('2019+.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2234 entries, 0 to 2233\n",
      "Data columns (total 36 columns):\n",
      "ATP           2234 non-null int64\n",
      "Location      2234 non-null object\n",
      "Tournament    2234 non-null object\n",
      "Date          2234 non-null datetime64[ns]\n",
      "Series        2234 non-null object\n",
      "Court         2234 non-null object\n",
      "Surface       2234 non-null object\n",
      "Round         2234 non-null object\n",
      "Best of       2234 non-null int64\n",
      "Winner        2234 non-null object\n",
      "Loser         2234 non-null object\n",
      "WRank         2230 non-null float64\n",
      "LRank         2221 non-null float64\n",
      "WPts          2231 non-null float64\n",
      "LPts          2221 non-null float64\n",
      "W1            2215 non-null float64\n",
      "L1            2215 non-null float64\n",
      "W2            2205 non-null float64\n",
      "L2            2205 non-null float64\n",
      "W3            1119 non-null float64\n",
      "L3            1119 non-null float64\n",
      "W4            265 non-null float64\n",
      "L4            265 non-null float64\n",
      "W5            96 non-null float64\n",
      "L5            96 non-null float64\n",
      "Wsets         2215 non-null float64\n",
      "Lsets         2215 non-null float64\n",
      "Comment       2234 non-null object\n",
      "B365W         2225 non-null float64\n",
      "B365L         2225 non-null float64\n",
      "PSW           2225 non-null float64\n",
      "PSL           2225 non-null float64\n",
      "MaxW          2234 non-null float64\n",
      "MaxL          2234 non-null float64\n",
      "AvgW          2234 non-null float64\n",
      "AvgL          2234 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(24), int64(2), object(9)\n",
      "memory usage: 628.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23634 entries, 0 to 23633\n",
      "Data columns (total 42 columns):\n",
      "ATP           23634 non-null int64\n",
      "Location      23634 non-null object\n",
      "Tournament    23634 non-null object\n",
      "Date          23634 non-null datetime64[ns]\n",
      "Series        23634 non-null object\n",
      "Court         23634 non-null object\n",
      "Surface       23634 non-null object\n",
      "Round         23634 non-null object\n",
      "Best of       23634 non-null int64\n",
      "Winner        23634 non-null object\n",
      "Loser         23634 non-null object\n",
      "WRank         23624 non-null float64\n",
      "LRank         23586 non-null float64\n",
      "WPts          23626 non-null float64\n",
      "LPts          23587 non-null float64\n",
      "W1            23483 non-null float64\n",
      "L1            23485 non-null float64\n",
      "W2            23260 non-null float64\n",
      "L2            23260 non-null float64\n",
      "W3            11173 non-null float64\n",
      "L3            11173 non-null float64\n",
      "W4            2200 non-null float64\n",
      "L4            2200 non-null float64\n",
      "W5            816 non-null float64\n",
      "L5            816 non-null float64\n",
      "Wsets         23482 non-null float64\n",
      "Lsets         23480 non-null float64\n",
      "Comment       23634 non-null object\n",
      "B365W         23540 non-null float64\n",
      "B365L         23561 non-null float64\n",
      "EXW           20834 non-null object\n",
      "EXL           20839 non-null float64\n",
      "LBW           20172 non-null float64\n",
      "LBL           20183 non-null float64\n",
      "PSW           23513 non-null float64\n",
      "PSL           23513 non-null float64\n",
      "SJW           10314 non-null float64\n",
      "SJL           10321 non-null float64\n",
      "MaxW          23609 non-null float64\n",
      "MaxL          23609 non-null float64\n",
      "AvgW          23609 non-null float64\n",
      "AvgL          23609 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(29), int64(2), object(10)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ext.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Best of</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>...</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2234.000000</td>\n",
       "      <td>2234.000000</td>\n",
       "      <td>2230.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2231.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2215.000000</td>\n",
       "      <td>2215.000000</td>\n",
       "      <td>2205.000000</td>\n",
       "      <td>2205.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2215.000000</td>\n",
       "      <td>2215.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2234.000000</td>\n",
       "      <td>2234.000000</td>\n",
       "      <td>2234.000000</td>\n",
       "      <td>2234.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.635184</td>\n",
       "      <td>3.453894</td>\n",
       "      <td>57.948430</td>\n",
       "      <td>79.944169</td>\n",
       "      <td>1723.479606</td>\n",
       "      <td>1104.742008</td>\n",
       "      <td>5.823928</td>\n",
       "      <td>4.190971</td>\n",
       "      <td>5.822676</td>\n",
       "      <td>4.043537</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200451</td>\n",
       "      <td>0.445147</td>\n",
       "      <td>1.850387</td>\n",
       "      <td>3.222966</td>\n",
       "      <td>1.937683</td>\n",
       "      <td>3.526445</td>\n",
       "      <td>2.002936</td>\n",
       "      <td>3.743693</td>\n",
       "      <td>1.871629</td>\n",
       "      <td>3.186124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.505220</td>\n",
       "      <td>0.837904</td>\n",
       "      <td>54.876823</td>\n",
       "      <td>76.409609</td>\n",
       "      <td>2022.360691</td>\n",
       "      <td>1145.908936</td>\n",
       "      <td>1.199468</td>\n",
       "      <td>1.828982</td>\n",
       "      <td>1.229490</td>\n",
       "      <td>1.840488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455321</td>\n",
       "      <td>0.577775</td>\n",
       "      <td>0.917769</td>\n",
       "      <td>3.228215</td>\n",
       "      <td>1.051800</td>\n",
       "      <td>3.723625</td>\n",
       "      <td>1.125870</td>\n",
       "      <td>4.409477</td>\n",
       "      <td>0.933585</td>\n",
       "      <td>2.769056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1740.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>3.477500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>1415.000000</td>\n",
       "      <td>12415.000000</td>\n",
       "      <td>12355.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>11.730000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>12.220000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>28.490000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ATP      Best of        WRank        LRank          WPts  \\\n",
       "count  2234.000000  2234.000000  2230.000000  2221.000000   2231.000000   \n",
       "mean     28.635184     3.453894    57.948430    79.944169   1723.479606   \n",
       "std      15.505220     0.837904    54.876823    76.409609   2022.360691   \n",
       "min       1.000000     3.000000     1.000000     1.000000     17.000000   \n",
       "25%      17.000000     3.000000    20.000000    36.000000    707.000000   \n",
       "50%      29.000000     3.000000    48.000000    64.000000    983.000000   \n",
       "75%      41.000000     3.000000    78.000000    98.000000   1740.000000   \n",
       "max      54.000000     5.000000   455.000000  1415.000000  12415.000000   \n",
       "\n",
       "               LPts           W1           L1           W2           L2  ...  \\\n",
       "count   2221.000000  2215.000000  2215.000000  2205.000000  2205.000000  ...   \n",
       "mean    1104.742008     5.823928     4.190971     5.822676     4.043537  ...   \n",
       "std     1145.908936     1.199468     1.828982     1.229490     1.840488  ...   \n",
       "min        3.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%      577.000000     6.000000     3.000000     6.000000     3.000000  ...   \n",
       "50%      830.000000     6.000000     4.000000     6.000000     4.000000  ...   \n",
       "75%     1205.000000     6.000000     6.000000     6.000000     6.000000  ...   \n",
       "max    12355.000000     7.000000     7.000000     7.000000     7.000000  ...   \n",
       "\n",
       "             Wsets        Lsets        B365W        B365L          PSW  \\\n",
       "count  2215.000000  2215.000000  2225.000000  2225.000000  2225.000000   \n",
       "mean      2.200451     0.445147     1.850387     3.222966     1.937683   \n",
       "std       0.455321     0.577775     0.917769     3.228215     1.051800   \n",
       "min       0.000000     0.000000     1.002000     1.070000     1.005000   \n",
       "25%       2.000000     0.000000     1.300000     1.660000     1.330000   \n",
       "50%       2.000000     0.000000     1.570000     2.300000     1.640000   \n",
       "75%       2.000000     1.000000     2.100000     3.500000     2.190000   \n",
       "max       3.000000     2.000000     9.000000    41.000000    11.730000   \n",
       "\n",
       "               PSL         MaxW         MaxL         AvgW         AvgL  \n",
       "count  2225.000000  2234.000000  2234.000000  2234.000000  2234.000000  \n",
       "mean      3.526445     2.002936     3.743693     1.871629     3.186124  \n",
       "std       3.723625     1.125870     4.409477     0.933585     2.769056  \n",
       "min       1.070000     1.010000     1.080000     1.010000     1.060000  \n",
       "25%       1.760000     1.360000     1.820000     1.310000     1.720000  \n",
       "50%       2.440000     1.670000     2.510000     1.600000     2.340000  \n",
       "75%       3.650000     2.270000     3.800000     2.120000     3.477500  \n",
       "max      37.800000    12.220000    67.000000     9.640000    28.490000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elo_rankings(data):\n",
    "    \"\"\"\n",
    "    Given the list on matches in chronological order, for each match, computes \n",
    "    the elo ranking of the 2 players at the beginning of the match\n",
    "    \"\"\"\n",
    "    print(\"Elo rankings computing...\")\n",
    "    players=list(pd.Series(list(data.Winner)+list(data.Loser)).value_counts().index)\n",
    "    elo=pd.Series(np.ones(len(players))*1500,index=players)\n",
    "    ranking_elo=[(1500,1500)]\n",
    "    for i in range(1,len(data)):\n",
    "        w=data.iloc[i-1,:].Winner\n",
    "        l=data.iloc[i-1,:].Loser\n",
    "        elow=elo[w]\n",
    "        elol=elo[l]\n",
    "        pwin=1 / (1 + 10 ** ((elol - elow) / 400))    \n",
    "        K_win=32\n",
    "        K_los=32\n",
    "        new_elow=elow+K_win*(1-pwin)\n",
    "        new_elol=elol-K_los*(1-pwin)\n",
    "        elo[w]=new_elow\n",
    "        elo[l]=new_elol\n",
    "        ranking_elo.append((elo[data.iloc[i,:].Winner],elo[data.iloc[i,:].Loser])) \n",
    "    ranking_elo=pd.DataFrame(ranking_elo,columns=[\"elo_winner\",\"elo_loser\"])    \n",
    "    ranking_elo[\"proba_elo\"]=1 / (1 + 10 ** ((ranking_elo[\"elo_loser\"] - ranking_elo[\"elo_winner\"]) / 400))   \n",
    "    return ranking_elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, \n",
    "                    features_to_drop=[], \n",
    "                    missing_values=\"drop\", \n",
    "                    drop_first=False):\n",
    "    \"\"\"\n",
    "    Processes raw data and returns a tuple (X, Y) where X is the cleaned dataset and Y is the array of labels.\n",
    "    \"\"\"\n",
    "    # Sort by date to calculate ELO\n",
    "    X = df.sort_values(by='Date')\n",
    "    \n",
    "    # Drop unuseful columns\n",
    "    features_to_drop += ['ATP', 'Location', 'Tournament', 'Date', 'Comment', \n",
    "                         'WPts', 'LPts', 'Wsets', 'Lsets', \n",
    "                         'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', \n",
    "                         'B365W', 'B365L', 'EXW', 'EXL', 'LBW', 'LBL', 'PSW', 'PSL', 'SJW', 'SJL']\n",
    "    X = X.drop(columns=features_to_drop)\n",
    "    \n",
    "    # Deal with missing values\n",
    "    X['WRank'] = X['WRank'].fillna(value=X['WRank'].max()+1).astype(int)\n",
    "    X['LRank'] = X['LRank'].fillna(value=X['LRank'].max()+1).astype(int)\n",
    "    \n",
    "    if missing_values == 'drop':\n",
    "        X = X.dropna()\n",
    "    elif missing_values == 'mean':\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        pass\n",
    "    elif missing_values == 'custom':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Wrong parameter: missing_values')\n",
    "\n",
    "    # Convert ordinal features to int (higher value means more important)\n",
    "    series = ['ATP250', 'ATP500', 'Masters 1000', 'Masters Cup', 'Grand Slam']\n",
    "    series2int = {s: i for i, s in enumerate(series)}\n",
    "    rounds2int = {'1st Round': 0,\n",
    "                  '2nd Round': 1,\n",
    "                  '3rd Round': 2,\n",
    "                  '4th Round': 3,\n",
    "                  'Round Robin': 4,\n",
    "                  'Quarterfinals': 5,\n",
    "                  'Semifinals': 6,\n",
    "                  'The Final': 7,\n",
    "                 }\n",
    "    X = X.replace({'Round': rounds2int, 'Series': series2int})\n",
    "    \n",
    "    # Convert court to binary\n",
    "    X = X.replace({'Court': {'Outdoor': 0, 'Indoor': 1}})\n",
    "    \n",
    "    # One hot encode categorical features into binary features\n",
    "    X = pd.get_dummies(X, prefix=['Surface_'], columns=['Surface'], drop_first=drop_first)\n",
    "    \n",
    "    # Convert players to numeric ?\n",
    "    players = set(X['Winner']) | set(X['Loser'])\n",
    "    players_to_id = {}\n",
    "    for i, player in enumerate(players):\n",
    "        players_to_id[player] = i\n",
    "    X = X.replace({'Winner': players_to_id, 'Loser': players_to_id})\n",
    "    X = X.astype({'Winner':int, 'Loser':int})\n",
    "\n",
    "    X = X.rename(columns={'Winner':'1st Player', 'Loser':'2nd Player', \n",
    "                          'WRank':'P1Rank', 'LRank':'P2Rank', \n",
    "                          'MaxW':'MaxP1', 'MaxL':'MaxP2', \n",
    "                          'AvgW':'AvgP1', 'AvgL':'AvgP2'})\n",
    "    \n",
    "    # Generate labels\n",
    "    Y = np.concatenate([np.ones(X.shape[0], dtype=int), np.zeros(X.shape[0], dtype=int)])\n",
    "    # Swap columns and concatenate to data\n",
    "    tmp = X.copy()\n",
    "    cols_to_swap = ['1st Player', '2nd Player', 'P1Rank', 'P2Rank', 'MaxP1', 'MaxP2',  'AvgP1',  'AvgP2']\n",
    "    cols_swapped = ['2nd Player', '1st Player', 'P2Rank', 'P1Rank', 'MaxP2', 'MaxP1',  'AvgP2',  'AvgP1']\n",
    "    tmp[cols_to_swap] = tmp[cols_swapped]\n",
    "    tmp.index = np.array(range(X.shape[0] + 1, X.shape[0] * 2 + 1))\n",
    "    X = pd.concat((X, tmp))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = preprocess_data(df_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(all(type(t) == np.int32 for t in labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47218 entries, 220 to 47218\n",
      "Data columns (total 15 columns):\n",
      "Series            47218 non-null int64\n",
      "Court             47218 non-null int64\n",
      "Round             47218 non-null int64\n",
      "Best of           47218 non-null int64\n",
      "1st Player        47218 non-null int32\n",
      "2nd Player        47218 non-null int32\n",
      "P1Rank            47218 non-null int32\n",
      "P2Rank            47218 non-null int32\n",
      "MaxP1             47218 non-null float64\n",
      "MaxP2             47218 non-null float64\n",
      "AvgP1             47218 non-null float64\n",
      "AvgP2             47218 non-null float64\n",
      "Surface__Clay     47218 non-null uint8\n",
      "Surface__Grass    47218 non-null uint8\n",
      "Surface__Hard     47218 non-null uint8\n",
      "dtypes: float64(4), int32(4), int64(4), uint8(3)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(X, Y):\n",
    "    # Division of dataset in training set and test set.\n",
    "    # Validation set not required since we're going to use cross-validation\n",
    "    # by GIORGIA: ma dove usi i parametri x e y? \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.25)\n",
    "    # do we need to preserve date ordering?\n",
    "    # test with decision trees\n",
    "    print(\"{:10} - {:10} - {:10} - {:10}\".format('Leaves', 'Train acc', 'Test acc', 'k-valid'))\n",
    "    for leaves in range(2, 50):\n",
    "        dt = tree.DecisionTreeClassifier(class_weight=\"balanced\",\n",
    "                                         max_leaf_nodes=leaves)\n",
    "        # 1st method, no validation set\n",
    "        # not sure if it's right the way it's done\n",
    "        dt.fit(X_train, Y_train)\n",
    "        train_acc = accuracy_score(y_true=Y_train, y_pred=dt.predict(X_train))\n",
    "        test_acc = accuracy_score(y_true=Y_test, y_pred=dt.predict(X_test))\n",
    "        \n",
    "        # 2nd method using cross validation, should perform better\n",
    "        dt = tree.DecisionTreeClassifier(class_weight=\"balanced\",\n",
    "                                         max_leaf_nodes=leaves)\n",
    "        scores = cross_val_score(dt, X_train, Y_train, \n",
    "                                 cv=5, scoring='accuracy')\n",
    "        \n",
    "        print(leaves, train_acc,test_acc, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaves     - Train acc  - Test acc   - k-valid   \n",
      "2 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "3 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "4 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "5 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "6 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "7 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "8 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "9 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "10 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "11 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "12 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "13 0.7008160844887471 0.6998729351969505 0.7000537277207106\n",
      "14 0.7008160844887471 0.6998729351969505 0.6999125446062111\n",
      "15 0.7008160844887471 0.6998729351969505 0.6999125446062111\n",
      "16 0.7008160844887471 0.6998729351969505 0.6999125446062111\n",
      "17 0.7008160844887471 0.6998729351969505 0.6999125446062111\n",
      "18 0.7008160844887471 0.6998729351969505 0.6993478201100254\n",
      "19 0.7008160844887471 0.6998729351969505 0.6991501557777828\n",
      "20 0.7008160844887471 0.6998729351969505 0.6992066369977772\n",
      "21 0.7010419902295767 0.6998729351969505 0.698783111571234\n",
      "22 0.7010419902295767 0.6998729351969505 0.6986701491312453\n",
      "23 0.7011549430999915 0.699703515459551 0.6990089846200724\n",
      "24 0.7011549430999915 0.699703515459551 0.6990654578669979\n",
      "25 0.7011549430999915 0.699703515459551 0.698896022182335\n",
      "26 0.7012678959704064 0.6988564167725541 0.6986983379123548\n",
      "27 0.7012678959704064 0.6988564167725541 0.6986983418994521\n",
      "28 0.7015785163640471 0.6989411266412537 0.698670101289455\n",
      "29 0.7016067545816508 0.6975857687420585 0.6982747526849808\n",
      "30 0.7016349927992546 0.6975010588733588 0.6983029932938524\n",
      "31 0.7016349927992546 0.6975010588733588 0.6981900468022528\n",
      "32 0.7016349927992546 0.6975010588733588 0.6981618101782272\n",
      "33 0.7018326603224805 0.6975010588733588 0.6981618101782272\n",
      "34 0.701973851410499 0.6975857687420585 0.6974840913497772\n",
      "35 0.701973851410499 0.6975857687420585 0.6975405725697715\n",
      "36 0.7021432807161212 0.6975010588733588 0.6966370325112397\n",
      "37 0.7025103775449694 0.6978398983481575 0.6962981451912735\n",
      "38 0.7026515686329878 0.6977551884794578 0.6950556022060909\n",
      "39 0.7027645215034027 0.6978398983481575 0.6962981890459666\n",
      "40 0.7029057125914212 0.6977551884794578 0.6965805871728694\n",
      "41 0.7029057125914212 0.6977551884794578 0.6955356766299051\n",
      "42 0.7029057125914212 0.6977551884794578 0.6954509547999136\n",
      "43 0.703018665461836 0.6976704786107581 0.6951403160630134\n",
      "44 0.7033292858554768 0.6972469292672596 0.6951403240360824\n",
      "45 0.7036116680315139 0.6971622193985599 0.695083842816088\n",
      "46 0.7038093355547398 0.6970775095298603 0.6952249820837741\n",
      "47 0.7039505266427583 0.6974163490046591 0.695196741473777\n",
      "48 0.7040070030779657 0.6975010588733588 0.6951120834283365\n",
      "49 0.7043176234716064 0.6975010588733588 0.6948862183480642\n"
     ]
    }
   ],
   "source": [
    "foo(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowload_ao2020_data():\n",
    "    \"\"\"\n",
    "    To get the data for the tournament? if we need to scrape these are the links of the matches\n",
    "    https://ausopen.com/tournament-schedule\n",
    "    https://ausopen.com/schedule#!8071\n",
    "    \"\"\"\n",
    "    \n",
    "def get_elo():\n",
    "    from requests import get\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primo Test con k-Nearest-Neighbor Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def kNN_fun(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    for k in range(1,30):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(X_train,Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(X_test)\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1  | Accuracy: 0.5766200762388818\n",
      "k: 2  | Accuracy: 0.5757729775518848\n",
      "k: 3  | Accuracy: 0.6033036848792884\n",
      "k: 4  | Accuracy: 0.6071156289707751\n",
      "k: 5  | Accuracy: 0.623718763235917\n",
      "k: 6  | Accuracy: 0.6195679796696315\n",
      "k: 7  | Accuracy: 0.6264294790343075\n",
      "k: 8  | Accuracy: 0.6271918678526048\n",
      "k: 9  | Accuracy: 0.6315120711562897\n",
      "k: 10  | Accuracy: 0.6324438797119865\n",
      "k: 11  | Accuracy: 0.6342227869546803\n",
      "k: 12  | Accuracy: 0.6354934349851757\n",
      "k: 13  | Accuracy: 0.6356628547225752\n",
      "k: 14  | Accuracy: 0.634561626429479\n",
      "k: 15  | Accuracy: 0.6375264718339687\n",
      "k: 16  | Accuracy: 0.6365099534095722\n",
      "k: 17  | Accuracy: 0.6388818297331639\n",
      "k: 18  | Accuracy: 0.6409148665819568\n",
      "k: 19  | Accuracy: 0.6425243540872512\n",
      "k: 20  | Accuracy: 0.6436255823803473\n",
      "k: 21  | Accuracy: 0.6415078356628547\n",
      "k: 22  | Accuracy: 0.6462515883100381\n",
      "k: 23  | Accuracy: 0.6433714527742482\n",
      "k: 24  | Accuracy: 0.6451503600169419\n",
      "k: 25  | Accuracy: 0.6442185514612452\n",
      "k: 26  | Accuracy: 0.6453197797543414\n",
      "k: 27  | Accuracy: 0.6479457856840322\n",
      "k: 28  | Accuracy: 0.6470139771283354\n",
      "k: 29  | Accuracy: 0.6465904277848369\n"
     ]
    }
   ],
   "source": [
    "kNN_fun(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otteniamo al più una precisione del 64% con k = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kNN_fun_MinMaxScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )\n",
    "\n",
    "def kNN_fun_StandardScaler(X, Y) : \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for k in range(1,20):\n",
    "\n",
    "        kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        kNN.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "        Y_pred = kNN.predict(scaler.transform(X_test))\n",
    "\n",
    "        # compute Accuracy\n",
    "        print (\"k:\", k,\" | Accuracy:\", accuracy_score(y_true=Y_test, y_pred=Y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN MinMax Scaler\n",
      "k: 1  | Accuracy: 0.5839898348157561\n",
      "k: 2  | Accuracy: 0.5802626005929691\n",
      "k: 3  | Accuracy: 0.5996611605252011\n",
      "k: 4  | Accuracy: 0.5958492164337146\n",
      "k: 5  | Accuracy: 0.6033036848792884\n",
      "k: 6  | Accuracy: 0.6042354934349852\n",
      "k: 7  | Accuracy: 0.6088098263447692\n",
      "k: 8  | Accuracy: 0.6058449809402795\n",
      "k: 9  | Accuracy: 0.607708598051673\n",
      "k: 10  | Accuracy: 0.6064379500211775\n",
      "k: 11  | Accuracy: 0.6144853875476493\n",
      "k: 12  | Accuracy: 0.6094027954256671\n",
      "k: 13  | Accuracy: 0.6131300296484541\n",
      "k: 14  | Accuracy: 0.6120288013553579\n",
      "k: 15  | Accuracy: 0.6108428631935621\n",
      "k: 16  | Accuracy: 0.6121135112240575\n",
      "k: 17  | Accuracy: 0.613977128335451\n",
      "k: 18  | Accuracy: 0.6104193138500635\n",
      "k: 19  | Accuracy: 0.6156713257094452\n",
      "kNN Standard Scaler\n",
      "k: 1  | Accuracy: 0.5987293519695045\n",
      "k: 2  | Accuracy: 0.6027954256670902\n",
      "k: 3  | Accuracy: 0.629140194832698\n",
      "k: 4  | Accuracy: 0.6309191020753918\n",
      "k: 5  | Accuracy: 0.642270224481152\n",
      "k: 6  | Accuracy: 0.6398136382888606\n",
      "k: 7  | Accuracy: 0.6464210080474375\n",
      "k: 8  | Accuracy: 0.6479457856840322\n",
      "k: 9  | Accuracy: 0.6552308343922066\n",
      "k: 10  | Accuracy: 0.6541296060991105\n",
      "k: 11  | Accuracy: 0.658280389665396\n",
      "k: 12  | Accuracy: 0.6572638712409996\n",
      "k: 13  | Accuracy: 0.6608216857263871\n",
      "k: 14  | Accuracy: 0.6604828462515883\n",
      "k: 15  | Accuracy: 0.6637865311308767\n",
      "k: 16  | Accuracy: 0.6615840745446845\n",
      "k: 17  | Accuracy: 0.6659042778483694\n",
      "k: 18  | Accuracy: 0.6623464633629818\n",
      "k: 19  | Accuracy: 0.6649724692926726\n"
     ]
    }
   ],
   "source": [
    "print (\"kNN MinMax Scaler\")\n",
    "kNN_fun_MinMaxScaler(data, labels)\n",
    "print (\"kNN Standard Scaler\")\n",
    "kNN_fun_StandardScaler(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test size : 0.33\n",
    "### Con kNN MinMax Scaler non andiamo oltre il 62%\n",
    "### Con kNN Standard Scaler abbiamo risultati migliori ma comunque non superiamo il 66%\n",
    "## Test size : 0.25\n",
    "### Con kNN MinMax Scaler non andiamo oltre il 61%\n",
    "### Con kNN Standard Scaler abbiamo risultati migliori ma comunque non superiamo il 66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
